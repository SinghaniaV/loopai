{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T16:14:17.231191812Z",
     "start_time": "2023-08-01T16:14:16.490140865Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import time\n",
    "from database.db_utils import get_connection\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### since, the smallest unit for which we have to measure the availability is an hour.\n",
    "### so, divide max(timestamp) - min(timestamp) into batches of 1 hour for each day.\n",
    "### look for available data in each of the batches.\n",
    "### if the store was active we mark the whole hour as available.\n",
    "### if the store was not active or the data is not available then we mark the whole hour as not available."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T16:25:20.471458589Z",
     "start_time": "2023-08-01T16:24:52.878350540Z"
    }
   },
   "outputs": [],
   "source": [
    "# connect to the database\n",
    "engine = get_connection()\n",
    "\n",
    "# load the tables into pd.Dataframes\n",
    "store_status_df: pd.DataFrame = pd.read_sql_table('store_status', con=engine)\n",
    "time_zone_df: pd.DataFrame = pd.read_sql_table('time_zone', con=engine)\n",
    "menu_hours_df: pd.DataFrame = pd.read_sql_table('menu_hours', con=engine)\n",
    "reports_df: pd.DataFrame = pd.read_sql_table('reports', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df = pd.merge(store_status_df, menu_hours_df, on='store_id', how='left')\n",
    "merged_df = pd.merge(merged_df, time_zone_df, on='store_id', how='left')\n",
    "\n",
    "merged_df['timestamp_utc'] = pd.to_datetime(merged_df['timestamp_utc'])\n",
    "merged_df['timestamp_utc'] = merged_df['timestamp_utc'].dt.tz_localize('UTC')\n",
    "\n",
    "merged_df['timezone_str'] = merged_df['timezone_str'].fillna('America/Chicago')\n",
    "merged_df['timestamp_local'] = merged_df\\\n",
    "    .apply(lambda row: row['timestamp_utc'].tz_convert(row['timezone_str']), axis=1)\n",
    "grouped = merged_df.groupby(by=['store_id'])\\\n",
    "    .agg(min_value=('timestamp_local', 'min'), max_value=('timestamp_local', 'max'))\n",
    "\n",
    "print(grouped)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T10:29:19.910186775Z",
     "start_time": "2023-08-01T10:29:19.811891350Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhead\u001B[49m(\u001B[38;5;241m5\u001B[39m))\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'generator' object has no attribute 'head'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
